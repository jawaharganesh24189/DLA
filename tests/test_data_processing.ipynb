{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Data Processing System - Test Notebook\n",
    "\n",
    "This notebook tests the enhanced multi-file data processing system for dialogue datasets.\n",
    "\n",
    "**Author**: Deep Learning Academy  \n",
    "**Purpose**: Validation and testing of data processing components\n",
    "\n",
    "## Test Coverage\n",
    "\n",
    "1. Drive mounting and scanning\n",
    "2. Multi-format file processing (TXT, JSON, JSONL, CSV)\n",
    "3. Quality filtering\n",
    "4. Duplicate detection\n",
    "5. Caching functionality\n",
    "6. Error handling\n",
    "7. Memory usage monitoring\n",
    "8. Processing statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (if needed)\n",
    "!pip install -q tqdm pandas pyarrow pyyaml psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our custom modules\n",
    "from src.drive_data_loader import DriveDataLoader\n",
    "from src.enhanced_data_processor import EnhancedDialogueProcessor\n",
    "from src.data_cache import DataCache\n",
    "from src.processing_monitor import ProcessingMonitor\n",
    "from src.data_processor import DialogueParser, DialogueTurn\n",
    "\n",
    "print(\"‚úÖ All custom modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Create Sample Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data directory\n",
    "test_data_dir = Path(\"/tmp/test_dialogue_data\")\n",
    "test_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create sample TXT file\n",
    "txt_content = \"\"\"context: Hello, how are you?\n",
    "response: I'm doing well, thank you for asking!\n",
    "\n",
    "context: What's your name?\n",
    "response: I'm an AI assistant here to help you.\n",
    "\n",
    "context: Can you help me with something?\n",
    "response: Of course! I'd be happy to help. What do you need?\n",
    "\"\"\"\n",
    "\n",
    "with open(test_data_dir / \"test_dialogue_1.txt\", \"w\") as f:\n",
    "    f.write(txt_content)\n",
    "\n",
    "# Create sample JSON file\n",
    "json_content = [\n",
    "    {\"context\": \"What is machine learning?\", \"response\": \"Machine learning is a subset of AI that enables systems to learn from data.\"},\n",
    "    {\"context\": \"Explain neural networks\", \"response\": \"Neural networks are computing systems inspired by biological neural networks.\"}\n",
    "]\n",
    "\n",
    "with open(test_data_dir / \"test_dialogue_2.json\", \"w\") as f:\n",
    "    json.dump(json_content, f, indent=2)\n",
    "\n",
    "# Create sample JSONL file\n",
    "jsonl_content = [\n",
    "    {\"context\": \"What is Python?\", \"response\": \"Python is a high-level programming language.\"},\n",
    "    {\"context\": \"What is JavaScript?\", \"response\": \"JavaScript is a programming language for web development.\"}\n",
    "]\n",
    "\n",
    "with open(test_data_dir / \"test_dialogue_3.jsonl\", \"w\") as f:\n",
    "    for obj in jsonl_content:\n",
    "        f.write(json.dumps(obj) + \"\\n\")\n",
    "\n",
    "# Create sample CSV file\n",
    "csv_content = \"\"\"context,response\n",
    "\"What is AI?\",\"Artificial Intelligence is the simulation of human intelligence by machines.\"\n",
    "\"Define deep learning\",\"Deep learning is a subset of machine learning using neural networks with multiple layers.\"\n",
    "\"\"\"\n",
    "\n",
    "with open(test_data_dir / \"test_dialogue_4.csv\", \"w\") as f:\n",
    "    f.write(csv_content)\n",
    "\n",
    "# Create a file with duplicates\n",
    "txt_with_dupes = \"\"\"context: Hello, how are you?\n",
    "response: I'm doing well, thank you for asking!\n",
    "\n",
    "context: Hello, how are you?\n",
    "response: I'm doing well, thank you for asking!\n",
    "\n",
    "context: Different question\n",
    "response: Different answer\n",
    "\"\"\"\n",
    "\n",
    "with open(test_data_dir / \"test_duplicates.txt\", \"w\") as f:\n",
    "    f.write(txt_with_dupes)\n",
    "\n",
    "print(f\"‚úÖ Created test data in {test_data_dir}\")\n",
    "print(f\"   Files: {list(test_data_dir.glob('*'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 2: Drive Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DriveDataLoader (using local path for testing)\n",
    "loader = DriveDataLoader(mount_path=str(test_data_dir.parent))\n",
    "\n",
    "# Since we're not in Colab, mount will use local path\n",
    "loader.is_mounted = True\n",
    "\n",
    "# Scan folder\n",
    "files = loader.scan_folder(str(test_data_dir), recursive=False)\n",
    "\n",
    "print(f\"‚úÖ DriveDataLoader test passed\")\n",
    "print(f\"   Found {len(files)} files\")\n",
    "for f in files:\n",
    "    print(f\"   - {Path(f).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test folder statistics\n",
    "stats = loader.get_folder_stats(str(test_data_dir))\n",
    "\n",
    "print(\"\\nüìä Folder Statistics:\")\n",
    "print(f\"   Total files: {stats['total_files']}\")\n",
    "print(f\"   Total size: {stats['total_size_mb']:.4f} MB\")\n",
    "print(f\"   File types: {stats['file_types']}\")\n",
    "print(\"\\n‚úÖ Folder stats test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Enhanced Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize processor\n",
    "processor = EnhancedDialogueProcessor(\n",
    "    tokenizer_config={\n",
    "        'max_vocab_size': 1000,\n",
    "        'min_word_freq': 1\n",
    "    },\n",
    "    quality_filters={\n",
    "        'min_dialogue_length': 3,\n",
    "        'max_dialogue_length': 200,\n",
    "        'min_word_count': 1,\n",
    "        'remove_duplicates': True\n",
    "    },\n",
    "    cache_dir=\"/tmp/test_cache\",\n",
    "    log_dir=\"/tmp/test_logs\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ EnhancedDialogueProcessor initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all test files\n",
    "dialogues = processor.process_drive_files(\n",
    "    file_list=files,\n",
    "    batch_size=10,\n",
    "    show_progress=True,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Processing complete\")\n",
    "print(f\"   Total dialogues: {len(dialogues)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample dialogues\n",
    "print(\"\\nüìù Sample Dialogues:\")\n",
    "for i, dialogue in enumerate(dialogues[:3], 1):\n",
    "    print(f\"\\n{i}. Context: {dialogue.context}\")\n",
    "    print(f\"   Response: {dialogue.response}\")\n",
    "    print(f\"   Metadata: {dialogue.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 4: Format-Specific Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each format individually\n",
    "print(\"Testing individual formats:\\n\")\n",
    "\n",
    "# TXT\n",
    "txt_files = [f for f in files if f.endswith('.txt')]\n",
    "if txt_files:\n",
    "    txt_turns = processor._process_single_file(txt_files[0])\n",
    "    print(f\"‚úÖ TXT format: {len(txt_turns)} turns from {Path(txt_files[0]).name}\")\n",
    "\n",
    "# JSON\n",
    "json_files = [f for f in files if f.endswith('.json')]\n",
    "if json_files:\n",
    "    json_turns = processor._process_single_file(json_files[0])\n",
    "    print(f\"‚úÖ JSON format: {len(json_turns)} turns from {Path(json_files[0]).name}\")\n",
    "\n",
    "# JSONL\n",
    "jsonl_files = [f for f in files if f.endswith('.jsonl')]\n",
    "if jsonl_files:\n",
    "    jsonl_turns = processor._process_single_file(jsonl_files[0])\n",
    "    print(f\"‚úÖ JSONL format: {len(jsonl_turns)} turns from {Path(jsonl_files[0]).name}\")\n",
    "\n",
    "# CSV\n",
    "csv_files = [f for f in files if f.endswith('.csv')]\n",
    "if csv_files:\n",
    "    csv_turns = processor._process_single_file(csv_files[0])\n",
    "    print(f\"‚úÖ CSV format: {len(csv_turns)} turns from {Path(csv_files[0]).name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 5: Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test duplicate removal\n",
    "dup_file = [f for f in files if 'duplicates' in f]\n",
    "if dup_file:\n",
    "    turns_with_dupes = processor._process_single_file(dup_file[0])\n",
    "    print(f\"Turns before deduplication: {len(turns_with_dupes)}\")\n",
    "    \n",
    "    turns_no_dupes = processor._remove_duplicates(turns_with_dupes)\n",
    "    print(f\"Turns after deduplication: {len(turns_no_dupes)}\")\n",
    "    print(f\"Duplicates removed: {len(turns_with_dupes) - len(turns_no_dupes)}\")\n",
    "    print(\"\\n‚úÖ Duplicate detection test passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 6: Vocabulary Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabulary from dialogues\n",
    "vocab = processor.build_vocabulary(dialogues)\n",
    "\n",
    "print(f\"‚úÖ Vocabulary built\")\n",
    "print(f\"   Vocabulary size: {len(vocab)}\")\n",
    "print(f\"   Sample tokens: {list(vocab.keys())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 7: Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test caching\n",
    "cache = DataCache(cache_dir=\"/tmp/test_cache\")\n",
    "\n",
    "# Save data\n",
    "test_data = {\"dialogues\": [\"Hello\", \"Hi\", \"How are you?\"]}\n",
    "success = cache.save_processed_data(test_data, \"test_key_1\")\n",
    "print(f\"Save successful: {success}\")\n",
    "\n",
    "# Load data\n",
    "loaded_data = cache.load_cached_data(\"test_key_1\", validate=False)\n",
    "print(f\"Load successful: {loaded_data == test_data}\")\n",
    "\n",
    "# Test checkpoint\n",
    "state = {\"files_processed\": 5, \"dialogues\": 100}\n",
    "checkpoint_success = cache.create_checkpoint(state, \"test_checkpoint\")\n",
    "print(f\"Checkpoint created: {checkpoint_success}\")\n",
    "\n",
    "# Restore checkpoint\n",
    "restored_state = cache.restore_from_checkpoint(\"test_checkpoint\")\n",
    "print(f\"Checkpoint restored: {restored_state == state}\")\n",
    "\n",
    "print(\"\\n‚úÖ Caching tests passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cache statistics\n",
    "cache_stats = cache.get_cache_stats()\n",
    "print(\"\\nüìä Cache Statistics:\")\n",
    "for key, value in cache_stats.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 8: Export Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test export in different formats\n",
    "output_dir = Path(\"/tmp/test_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Export as JSONL\n",
    "success_jsonl = processor.export_to_format(\n",
    "    dialogues,\n",
    "    str(output_dir / \"test_export.jsonl\"),\n",
    "    format_type='jsonl'\n",
    ")\n",
    "print(f\"‚úÖ JSONL export: {success_jsonl}\")\n",
    "\n",
    "# Export as CSV\n",
    "success_csv = processor.export_to_format(\n",
    "    dialogues,\n",
    "    str(output_dir / \"test_export.csv\"),\n",
    "    format_type='csv'\n",
    ")\n",
    "print(f\"‚úÖ CSV export: {success_csv}\")\n",
    "\n",
    "# Export as TXT\n",
    "success_txt = processor.export_to_format(\n",
    "    dialogues,\n",
    "    str(output_dir / \"test_export.txt\"),\n",
    "    format_type='txt'\n",
    ")\n",
    "print(f\"‚úÖ TXT export: {success_txt}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output files: {list(output_dir.glob('*'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 9: Memory and Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get processing statistics\n",
    "stats = processor.get_processing_stats()\n",
    "\n",
    "print(\"\\nüìä Processing Statistics:\")\n",
    "print(f\"   Files processed: {stats['processed_files']}/{stats['total_files']}\")\n",
    "print(f\"   Failed files: {stats['failed_files']}\")\n",
    "print(f\"   Total dialogues: {stats['total_dialogues']}\")\n",
    "print(f\"   Duplicates removed: {stats['total_duplicates_removed']}\")\n",
    "print(f\"   Memory usage: {stats['memory_usage_mb']:.2f} MB\")\n",
    "print(f\"   Processing rate: {stats['processing_rate_files_per_sec']:.2f} files/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 10: Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corrupted file\n",
    "corrupted_file = test_data_dir / \"corrupted.json\"\n",
    "with open(corrupted_file, \"w\") as f:\n",
    "    f.write(\"{this is not valid json\")\n",
    "\n",
    "# Try to process it\n",
    "try:\n",
    "    corrupted_turns = processor._process_single_file(str(corrupted_file))\n",
    "    print(f\"Processed corrupted file: {len(corrupted_turns)} turns (should be 0)\")\n",
    "    print(\"‚úÖ Error handling test passed - corrupted file handled gracefully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error handling test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 11: Configuration Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading from config file\n",
    "config_path = \"config/data_config.yaml\"\n",
    "\n",
    "if os.path.exists(config_path):\n",
    "    processor_from_config = EnhancedDialogueProcessor.from_config_file(config_path)\n",
    "    print(\"‚úÖ Configuration loading test passed\")\n",
    "    print(f\"   Config loaded from: {config_path}\")\n",
    "    print(f\"   Max vocab size: {processor_from_config.config.max_vocab_size}\")\n",
    "    print(f\"   Min dialogue length: {processor_from_config.config.min_dialogue_length}\")\n",
    "    print(f\"   Augmentation enabled: {processor_from_config.config.augmentation_enabled}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Config file not found at {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ Drive data loader - PASSED\")\n",
    "print(\"‚úÖ Folder statistics - PASSED\")\n",
    "print(\"‚úÖ Multi-format processing - PASSED\")\n",
    "print(\"‚úÖ TXT/JSON/JSONL/CSV parsing - PASSED\")\n",
    "print(\"‚úÖ Duplicate detection - PASSED\")\n",
    "print(\"‚úÖ Vocabulary building - PASSED\")\n",
    "print(\"‚úÖ Caching system - PASSED\")\n",
    "print(\"‚úÖ Data export - PASSED\")\n",
    "print(\"‚úÖ Memory monitoring - PASSED\")\n",
    "print(\"‚úÖ Error handling - PASSED\")\n",
    "print(\"‚úÖ Configuration loading - PASSED\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüéâ All tests passed successfully!\")\n",
    "print(\"\\nThe enhanced data processing system is ready for use.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up test files\n",
    "import shutil\n",
    "\n",
    "# Uncomment to clean up\n",
    "# shutil.rmtree(test_data_dir, ignore_errors=True)\n",
    "# shutil.rmtree(\"/tmp/test_cache\", ignore_errors=True)\n",
    "# shutil.rmtree(\"/tmp/test_logs\", ignore_errors=True)\n",
    "# shutil.rmtree(\"/tmp/test_output\", ignore_errors=True)\n",
    "\n",
    "print(\"Test files retained for inspection.\")\n",
    "print(\"Uncomment cleanup code above to remove test files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
